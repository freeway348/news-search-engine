<?xml version='1.0' encoding='utf-8'?>
<doc><id>1182</id><url>http://www.chinanews.com/fz/2025/06-14/10432042.shtml</url><title>真人“数字人”傻傻分不清</title><datetime>2025-6-14 03:50:00</datetime><body>	真人“数字人”傻傻分不清
	专家：细化技术标准让“AI数字人”透明化合规化
	□本报记者　赵丽
	□本报实习生宋昕怡
	“生西红柿和生黄瓜不能一起吃了！黄瓜中的分解酶会破坏维生素C，一起吃轻则影响西红柿中维生素C的吸收，重则可能导致腹泻、肠胃不适甚至食物中毒。”电话那头，母亲说得头头是道，电话这头的赵女士却听得一头雾水。
	随即，母亲发来一则视频。赵女士回忆说：“一位满头花白头发、身着白大褂的‘医生’在视频里侃侃而谈‘养生秘籍’，甚至宣称‘清淡饮食就是只吃素食，完全不吃肉’。我妈把这个‘医生’的话奉为圭臬。”但赵女士仔细查看后，在视频右下角发现一串几乎透明的标注——“此视频由AI辅助生成”。
	“后来，我妈戴着老花镜，在我的指点下找了一会儿才看见那行字。”赵女士无奈地说，“这也不能怪老人，现在AI生成的‘数字人’泛滥，还难辨真假，实在让人防不胜防。”
	有此困扰的并非只有赵女士一家。《法治日报》记者近日随机采访了数十名路人，至少有七成受访者称曾刷到过“AI数字人”视频，并且“难以分清到底是真人还是‘数字人’”，而原因主要在于“找不到有效提示”。
	很多人担忧：真人“数字人”傻傻分不清楚，背后是肖像权侵权乃至敲诈、诈骗等违法犯罪的风险隐患。
	是否数字人难辨别
	在重庆读大学的郑媛浏览某社交平台时，刷到一则帖子——照片里的女生外形温婉可人，穿搭清爽时尚，很夺人眼球。郑媛点赞并关注了该账号。
	但不多时，郑媛却刷到另一名博主揭露用“AI生成人”起号的内容，被打假的恰恰是她先前所关注的这个账号。“我仔细翻阅了那个女生的账号主页，她并未标明使用AI技术，还在评论区亲切地与其他用户互动。”面对这样的局面，郑媛说自己也“糊涂了”。她后来观察了一个多星期，找到了该账号图片确为AI生成的证据——有网友在其他账号上发现了妆容和衣着几乎一样的“数字人”，而人物介绍却完全不同。
	习惯在直播间购物的北京市民李菲说，自己经常误入“数字人”直播间，“数字人”主播侃侃而谈介绍商品，手部动作还能随着她说话的节奏不断变动，声音流畅而自然。
	“要仔细看才能看到直播间左侧一行‘现直播内容为数字人直播，非真人直播’的小字提醒。”李菲说，自己现在习惯了进直播间“先找小字”，确认主播是否为真人，“但真的‘费眼睛’，不是在犄角旮旯，就是字体几乎透明，不注意根本看不到”。
	袁伟(化名)是某985高校计算机系研究生。他告诉记者：“现在一些AI大模型生成的图，别说中老年人会误以为真，很多没怎么接触过AI技术的年轻人都不见得能分辨真假。”
	他随即为记者演示，向某AI软件输入指令“帮我生成图片：一个容貌姣好的女性，精细的皮肤纹理，室外自然光”，随即生成的图片与真人照片相差无几，如果不是右下角自带的水印，只让人觉得是一张普通的美女照片。“如果说早期的AI软件大多不能生成自然的手指和人体比例，现在技术进步得很快，生成的手指和人体比例已经比较像样了，更加大了分辨的难度。”
	“这样的AI生成图片或视频，如果不作标识提示，会让很多人信以为真。”袁伟说。
	大量账号未作标识
	记者在某社交平台上注意到一名为“××AI打假人”的账户，其发帖称自己将致力于“揪出纯AI生成的内容博主，帮小白识别真伪”，还表示“关注了很多AI生成非真实的帅哥美女”。
	在其关注列表里有300多个账号，记者随机选取了其中20个账号浏览发现，若没有看到评论区“这是AI吧，手指的细节很诡异”“背景里的文字都是乱码”等留言，记者第一反应只以为他们是普通的颜值时尚类博主。
	这20个粉丝量几百到几万不等的账号，仅有3个账号在简介中写明“虚拟男友”“AI”“友情提示视频由虚拟现实技术制作”，两个账号主页的内容经平台审核后被打上了“疑似包含AI创作信息，请谨慎甄别”的标签。其余账号在简介、内容中并未提及“AI”字眼，平台的监测机制也并未识别到，这些账号甚至还在评论区熟稔地与其他用户互动，让自己看上去更有“真人感”。
	在调查过程中，有超过一半的受访者向记者表示AI生成的“数字人”和真人难以分辨，相关的提示也并不显眼。
	此外，记者发现，有人还会特意教人如何绕过平台的“AI打标”。据了解，目前，各平台已普遍升级AI内容识别系统，要求对AI生成作品进行显著标注。但在调查中，有分享经验的博主表示花费不到千元就可以购买所谓的AI工具中预配置的镜像文件，称用这些镜像参数一键生成的虚拟人形象可以以假乱真，最大限度规避平台的AI内容强制标注机制。
	细化标准加大惩处
	记者梳理公开信息发现，实践中，一些有心人士利用“数字人”形象行不法之事。
	据报道，张文宏、雷军等公众人物形象曾被利用生成“AI数字人”，用来带货、恶搞。一些直播间内，“AI数字人”向中老年人群体虚假宣传保健品，诱导购买。更有甚者，一些不法分子利用“AI数字人”进行敲诈、诈骗等犯罪。例如，山西忻州公安机关工作发现，犯罪嫌疑人王某某利用AI技术，制作合成“数字人”新闻视频引流，进而进行有偿发帖、有偿删帖等敲诈勒索活动。2024年，江西一名65岁老人到银行办理业务，声称要贷款200万元给男朋友“靳东”拍戏，后经调查，老人手机里的“靳东”视频是AI合成的。
	重庆大学网络与大数据研究院副院长罗勇认为，就价值取向而言，AI产业发展不能凌驾于网络安全之上。对于利用AI技术生成的短视频，网络用户特别是未成年人和老年人由于缺乏必要的鉴别能力，往往会信以为真，由此可能产生负面网络舆情，甚至对网络安全造成负面影响。
	据受访专家介绍，当前我国已经出台了《生成式人工智能服务管理暂行办法》《互联网信息服务深度合成管理规定》等法规，对“AI数字人”和AI生成内容的标识、数据来源等提出了具体要求。
	今年3月，国家网信办等四部门联合发布《人工智能生成合成内容标识办法》(以下简称标识办法)，通过标识提醒用户辨别虚假信息，规范内容制作、传播各环节标识行为，为规范AI生成内容划定红线。该办法将于9月1日起施行。
	中国政法大学教授郑飞指出，相关规定一定程度存在落地难的问题。一是监管和技术手段有限，难以彻底发现并纠正违规行为。例如，一些“AI起号”从业者通过预置“镜像参数”生成极为逼真的虚拟人像，从而逃避平台的强制标注要求。而监管部门特别是基层执法部门，通常面临职责不清、执法手段和执法力量不足的问题；二是部分平台在一定程度上“管不了”也“不想管”。“管不了”在于平台管理能力与技术手段欠缺，尤其是一些小型平台，缺乏足够的审核人力和技术支持。“不想管”则是背后利益驱动。未明显标识“AI数字人”或合成内容，会让受众误以为是真人或真实事件，从而更容易引起人们的兴趣和好奇心，吸引更多的流量和关注，进而带来更多的商业利益。
	“以网络社交平台为代表的网络服务提供者在AI生成内容的应用场景中，应当进一步完善用户使用AI协议规定，并强化对AI生成内容的审核。”罗勇说。
	郑飞建议，应从明确标识要求和加大责任追究两方面发力。标识办法明确要求，一旦检测到AI生成内容，传播平台应在发布内容周边添加显著提示标识，并在文件元数据中加隐式标识，确保全流程可溯源。在未来落实过程中，可进一步细化技术标准，比如规定标识文字的最小高度、对比度、展示时长等，让标识一目了然。另外，对于不按规定标注的行为，需要严厉处罚：除加大行政罚款、暂停业务或纳入不良信用记录等行政措施外，还要利用法律手段加大威慑。通过明确、显著的标识标准和更严厉的责任追究，才能从根本上震慑违规不标注行为，实现“AI数字人”应用的透明化、合规化。【编辑:杨亚龙】
</body></doc>