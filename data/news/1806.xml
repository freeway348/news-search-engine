<?xml version='1.0' encoding='utf-8'?>
<doc><id>1806</id><url>http://www.chinanews.com/sh/2025/06-03/10426321.shtml</url><title>用“AI率”对论文“一票否决”科学吗</title><datetime>2025-6-3 14:03:00</datetime><body>	【创新谈】
	眼下正值2025年毕业季，多所高校出台规定，对毕业论文中人工智能(AI)生成内容比例提出明确要求，有的高校还将“AI率”高低与论文能否合格直接挂钩。
	显然，出台这一新规的初衷是为了防范学术不端。毕竟AI太强大，有些人在论文写作上动起歪脑筋，或让AI代写，或借AI编案例、造数据。但AI检测新规又带来新的问题：有毕业生在社交平台哀叹，明明是自己写的，检测系统偏偏说出自AI之手。用AI写作者则分享降“AI率”秘籍，如少用逗号、删减衔接词、打乱段落结构、多用口语化表达等等。甚至有商家声称深谙检测规则，兜售降“AI率”服务，进而催生出一条“检测—降低—再检测”的产业链。
	业内人士介绍，“AI率”检测的核心逻辑是分析文本的词汇词频、句式结构、逻辑表达等特征，将其与AI模型输出内容进行拟合，从而判断相似度。但这存在一个悖论——AI生成内容本身就是对人类语言的模仿，它追求规范性、逻辑性，这又恰恰与学术写作的要求高度重合。所以，AI检测结果存在先天缺陷，误判在所难免——原创文章可能会被判成AI生成，AI生成内容也可借技术漏洞蒙混过关。
	有人将朱自清的名篇《荷塘月色》上传至某常用论文检测系统，结果显示其AI生成内容中“总体疑似度超过六成”。一位高校教师在朋友圈吐槽，系统标红的“高度疑似AI生成”学术论文段落，由研究团队耗时3年扎根基层、追踪多个真实案例写成。
	“AI率”检测引发的争议，是技术变革时代下教育面临挑战的一个缩影。我们渴望用确定性方案消除AI的负面影响，但让AI检测AI本质上还是一种技术迷信。它可能迫使原创作者为降低“AI率”而进行无意义的修改，最终产出平庸甚至糟糕的文本。
	AI检测工具给出的数据，只能是一种参考，学术委员会才是最终把关人。有教师表示，学生的文章是否由AI写就，自己一看便知。毕竟，教师对学生的日常水平和研究过程是最了解的。基于教育过程的专业判断，应该优于任何模型。而且，论文质量高低，在学界也早有成熟的评判标准，与其纠结字词句的表述是否有“AI味”，不如看论文是否有独立思考，是否提供创新观点，研究方法是否恰当，数据和结论是否可靠，等等。总之，能为论文打出公正分，是导师、是审稿人，而不是任何一种AI工具。
	我们要培养的，不是能通过AI检测的写手，而是具备独立思考能力和创新思维的人。AI可以介入学术生产和学术评价流程，但其作用和功能只能是辅助性的。任何时候，人的主体性在学术评价中都不可替代。
	来源：科技日报张盖伦【编辑:于晓】
</body></doc>